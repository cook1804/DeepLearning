{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5872fdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "38/38 [==============================] - 0s 617us/step - loss: 0.2433 - accuracy: 0.5541\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 514us/step - loss: 0.2252 - accuracy: 0.6485\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 491us/step - loss: 0.2137 - accuracy: 0.6285\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 484us/step - loss: 0.1938 - accuracy: 0.7574\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 479us/step - loss: 0.1860 - accuracy: 0.7944\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.1781 - accuracy: 0.7272\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.1682 - accuracy: 0.7906\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.1445 - accuracy: 0.8185\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 513us/step - loss: 0.1508 - accuracy: 0.7689\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 514us/step - loss: 0.1436 - accuracy: 0.8115\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.1365 - accuracy: 0.8248\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.1180 - accuracy: 0.8388\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.1218 - accuracy: 0.8581\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 474us/step - loss: 0.1126 - accuracy: 0.8698\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.1212 - accuracy: 0.8424\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.1198 - accuracy: 0.8499\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.1116 - accuracy: 0.8518\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 500us/step - loss: 0.0993 - accuracy: 0.8635\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 488us/step - loss: 0.0989 - accuracy: 0.8645\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0972 - accuracy: 0.8644\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0873 - accuracy: 0.8935\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.1134 - accuracy: 0.8371\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.1068 - accuracy: 0.8306\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 508us/step - loss: 0.1003 - accuracy: 0.8405\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0742 - accuracy: 0.9225\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0908 - accuracy: 0.9049\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 481us/step - loss: 0.1025 - accuracy: 0.8731\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 512us/step - loss: 0.0692 - accuracy: 0.9112\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0835 - accuracy: 0.9217\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0796 - accuracy: 0.9256\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 494us/step - loss: 0.0942 - accuracy: 0.8618\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 492us/step - loss: 0.0734 - accuracy: 0.9401\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0722 - accuracy: 0.9149\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0817 - accuracy: 0.8960\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0650 - accuracy: 0.9409\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 512us/step - loss: 0.0745 - accuracy: 0.9068\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 512us/step - loss: 0.0722 - accuracy: 0.9319\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 472us/step - loss: 0.0621 - accuracy: 0.9350\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 505us/step - loss: 0.0535 - accuracy: 0.9455\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 508us/step - loss: 0.0441 - accuracy: 0.9784\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0698 - accuracy: 0.9459\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 512us/step - loss: 0.0550 - accuracy: 0.9347\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 520us/step - loss: 0.0481 - accuracy: 0.9664\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 497us/step - loss: 0.0745 - accuracy: 0.8884\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0456 - accuracy: 0.9619\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 512us/step - loss: 0.0396 - accuracy: 0.9852\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0428 - accuracy: 0.9689\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 512us/step - loss: 0.0597 - accuracy: 0.9088\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 517us/step - loss: 0.0511 - accuracy: 0.9354\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0385 - accuracy: 0.9720\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 535us/step - loss: 0.0380 - accuracy: 0.9729\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 518us/step - loss: 0.0406 - accuracy: 0.9696\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 566us/step - loss: 0.0327 - accuracy: 0.9823\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 500us/step - loss: 0.0319 - accuracy: 0.9874\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 497us/step - loss: 0.0293 - accuracy: 0.9926\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 513us/step - loss: 0.0422 - accuracy: 0.9852\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 555us/step - loss: 0.0488 - accuracy: 0.9641\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 499us/step - loss: 0.0411 - accuracy: 0.9701\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 521us/step - loss: 0.0318 - accuracy: 0.9778\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 501us/step - loss: 0.0397 - accuracy: 0.9658\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 539us/step - loss: 0.0357 - accuracy: 0.9721\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 526us/step - loss: 0.0335 - accuracy: 0.9696\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 489us/step - loss: 0.0341 - accuracy: 0.9644\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 512us/step - loss: 0.0324 - accuracy: 0.9707\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 498us/step - loss: 0.0405 - accuracy: 0.9633\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 497us/step - loss: 0.0262 - accuracy: 0.9906\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0222 - accuracy: 0.9927\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 487us/step - loss: 0.0212 - accuracy: 0.9868\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 532us/step - loss: 0.0248 - accuracy: 0.9841\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 509us/step - loss: 0.0221 - accuracy: 0.9841\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 484us/step - loss: 0.0249 - accuracy: 0.9834\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 431us/step - loss: 0.0205 - accuracy: 0.9829\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 537us/step - loss: 0.0180 - accuracy: 0.9898\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0166 - accuracy: 0.9863\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 500us/step - loss: 0.0181 - accuracy: 0.9842\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 512us/step - loss: 0.0174 - accuracy: 0.9957\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 512us/step - loss: 0.0138 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 486us/step - loss: 0.0148 - accuracy: 0.9906\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0129 - accuracy: 0.9949\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 515us/step - loss: 0.0114 - accuracy: 0.9983\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 485us/step - loss: 0.0141 - accuracy: 0.9955\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 512us/step - loss: 0.0151 - accuracy: 0.9991\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0098 - accuracy: 0.9958\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0204 - accuracy: 0.9940\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0250 - accuracy: 0.9784\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0184 - accuracy: 0.9937\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0087 - accuracy: 0.9981\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 453us/step - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 476us/step - loss: 0.0066 - accuracy: 0.9993\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0054 - accuracy: 1.0000\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x00000230C2601D30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2494 - accuracy: 0.7143\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 0s 608us/step - loss: 0.2519 - accuracy: 0.4748\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 565us/step - loss: 0.2476 - accuracy: 0.5645\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.2378 - accuracy: 0.6060\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.2214 - accuracy: 0.7813\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.2033 - accuracy: 0.7136\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.1837 - accuracy: 0.7811\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 497us/step - loss: 0.1618 - accuracy: 0.8101\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 471us/step - loss: 0.1513 - accuracy: 0.8174\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.1488 - accuracy: 0.7901\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.1430 - accuracy: 0.8268\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 459us/step - loss: 0.1580 - accuracy: 0.7775\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 454us/step - loss: 0.1290 - accuracy: 0.8379\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.1342 - accuracy: 0.8226\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.1264 - accuracy: 0.8310\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 477us/step - loss: 0.1203 - accuracy: 0.8298\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.1334 - accuracy: 0.8191\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.1308 - accuracy: 0.8129\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 481us/step - loss: 0.1099 - accuracy: 0.8660\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 476us/step - loss: 0.1249 - accuracy: 0.8236\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 459us/step - loss: 0.1212 - accuracy: 0.8554\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 468us/step - loss: 0.1204 - accuracy: 0.8387\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.1172 - accuracy: 0.8128\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.1052 - accuracy: 0.8774\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 472us/step - loss: 0.1318 - accuracy: 0.8342\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0965 - accuracy: 0.8732\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0960 - accuracy: 0.8979\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.1097 - accuracy: 0.8819\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 491us/step - loss: 0.0976 - accuracy: 0.8819\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 487us/step - loss: 0.1040 - accuracy: 0.8602\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0941 - accuracy: 0.8968\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0999 - accuracy: 0.8653\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0861 - accuracy: 0.9199\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0841 - accuracy: 0.8982\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 501us/step - loss: 0.0730 - accuracy: 0.9242\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0959 - accuracy: 0.8639\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 496us/step - loss: 0.0748 - accuracy: 0.9193\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 505us/step - loss: 0.0754 - accuracy: 0.9268\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0810 - accuracy: 0.9042\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 469us/step - loss: 0.0868 - accuracy: 0.8838\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0899 - accuracy: 0.8944\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0838 - accuracy: 0.8983\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0812 - accuracy: 0.8902\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 484us/step - loss: 0.0766 - accuracy: 0.9037\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 510us/step - loss: 0.0744 - accuracy: 0.9247\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 512us/step - loss: 0.0506 - accuracy: 0.9577\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 532us/step - loss: 0.0745 - accuracy: 0.9303\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 515us/step - loss: 0.0745 - accuracy: 0.9195\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 507us/step - loss: 0.0916 - accuracy: 0.9255\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0663 - accuracy: 0.9275\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0566 - accuracy: 0.9425\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 511us/step - loss: 0.0564 - accuracy: 0.9580\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 525us/step - loss: 0.0838 - accuracy: 0.8845\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 485us/step - loss: 0.0573 - accuracy: 0.9401\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0531 - accuracy: 0.9539\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0574 - accuracy: 0.9362\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0646 - accuracy: 0.9503\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0649 - accuracy: 0.9238\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0518 - accuracy: 0.9607\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0735 - accuracy: 0.9228\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0569 - accuracy: 0.9508\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0573 - accuracy: 0.9236\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0489 - accuracy: 0.9606\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 461us/step - loss: 0.0457 - accuracy: 0.9734\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0602 - accuracy: 0.9378\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 474us/step - loss: 0.0502 - accuracy: 0.9374\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 491us/step - loss: 0.0419 - accuracy: 0.9606\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 497us/step - loss: 0.0487 - accuracy: 0.9700\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 512us/step - loss: 0.0578 - accuracy: 0.9314\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 466us/step - loss: 0.0456 - accuracy: 0.9623\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 512us/step - loss: 0.0429 - accuracy: 0.9793\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 475us/step - loss: 0.0493 - accuracy: 0.9373\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 512us/step - loss: 0.0321 - accuracy: 0.9769\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 515us/step - loss: 0.0446 - accuracy: 0.9536\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 499us/step - loss: 0.0318 - accuracy: 0.9643\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0485 - accuracy: 0.9554\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 501us/step - loss: 0.0360 - accuracy: 0.9710\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 477us/step - loss: 0.0294 - accuracy: 0.9860\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0330 - accuracy: 0.9790\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 480us/step - loss: 0.0318 - accuracy: 0.9743\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 476us/step - loss: 0.0342 - accuracy: 0.9833\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0307 - accuracy: 0.9843\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0323 - accuracy: 0.9707\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0377 - accuracy: 0.9724\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0321 - accuracy: 0.9783\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0303 - accuracy: 0.9822\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0288 - accuracy: 0.9806\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0245 - accuracy: 0.9734\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0222 - accuracy: 0.9909\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0241 - accuracy: 0.9817\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0329 - accuracy: 0.9710\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0170 - accuracy: 0.9912\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 472us/step - loss: 0.0204 - accuracy: 0.9925\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0272 - accuracy: 0.9624\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0132 - accuracy: 0.9935\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0222 - accuracy: 0.9782\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 475us/step - loss: 0.0162 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 459us/step - loss: 0.0269 - accuracy: 0.9782\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0127 - accuracy: 0.9971\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 505us/step - loss: 0.0123 - accuracy: 0.9983\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0153 - accuracy: 0.9932\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x00000230C3B2D160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2040 - accuracy: 0.6667\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 0s 777us/step - loss: 0.2713 - accuracy: 0.4422\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 502us/step - loss: 0.2399 - accuracy: 0.6761\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 499us/step - loss: 0.2397 - accuracy: 0.6172\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 464us/step - loss: 0.2260 - accuracy: 0.7115\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.2244 - accuracy: 0.6946\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 461us/step - loss: 0.2225 - accuracy: 0.6851\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.2083 - accuracy: 0.7696\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 501us/step - loss: 0.1964 - accuracy: 0.7642\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 497us/step - loss: 0.1870 - accuracy: 0.7698\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 474us/step - loss: 0.1869 - accuracy: 0.7415\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.1812 - accuracy: 0.7166\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 447us/step - loss: 0.1643 - accuracy: 0.7954\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.1590 - accuracy: 0.7913\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.1633 - accuracy: 0.7706\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 494us/step - loss: 0.1547 - accuracy: 0.8156\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.1171 - accuracy: 0.80 - 0s 512us/step - loss: 0.1614 - accuracy: 0.7507\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 478us/step - loss: 0.1466 - accuracy: 0.8310\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 473us/step - loss: 0.1400 - accuracy: 0.8170\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.1427 - accuracy: 0.8389\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.1320 - accuracy: 0.8177\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 480us/step - loss: 0.1468 - accuracy: 0.8277\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 476us/step - loss: 0.1318 - accuracy: 0.8165\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.1324 - accuracy: 0.8500\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 512us/step - loss: 0.1356 - accuracy: 0.8199\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 494us/step - loss: 0.1055 - accuracy: 0.8634\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 513us/step - loss: 0.1230 - accuracy: 0.8354\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 484us/step - loss: 0.1170 - accuracy: 0.8792\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 507us/step - loss: 0.0879 - accuracy: 0.9237\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 484us/step - loss: 0.0956 - accuracy: 0.8890\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.1135 - accuracy: 0.8614\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.1093 - accuracy: 0.8782\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 497us/step - loss: 0.1206 - accuracy: 0.8687\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0904 - accuracy: 0.8910\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0819 - accuracy: 0.9050\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0795 - accuracy: 0.9165\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.1043 - accuracy: 0.8458\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.1071 - accuracy: 0.8867\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0919 - accuracy: 0.8893\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.1011 - accuracy: 0.8870\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0765 - accuracy: 0.9254\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0934 - accuracy: 0.8727\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0880 - accuracy: 0.8705\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0723 - accuracy: 0.9053\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.1016 - accuracy: 0.8600\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0848 - accuracy: 0.9146\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0749 - accuracy: 0.8954\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0683 - accuracy: 0.9335\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0802 - accuracy: 0.8976\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0566 - accuracy: 0.9543\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0636 - accuracy: 0.9305\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0585 - accuracy: 0.9591\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0890 - accuracy: 0.9009\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0605 - accuracy: 0.9431\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0740 - accuracy: 0.9111\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0771 - accuracy: 0.8778\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0650 - accuracy: 0.9312\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0686 - accuracy: 0.9326\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0535 - accuracy: 0.9454\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0687 - accuracy: 0.9538\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 512us/step - loss: 0.0539 - accuracy: 0.9480\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0614 - accuracy: 0.9419\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0412 - accuracy: 0.9674\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0574 - accuracy: 0.9285\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0749 - accuracy: 0.8972\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 566us/step - loss: 0.0507 - accuracy: 0.9495\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 512us/step - loss: 0.0467 - accuracy: 0.9349\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 1.00 - 0s 533us/step - loss: 0.0569 - accuracy: 0.9487\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 515us/step - loss: 0.0389 - accuracy: 0.9683\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0407 - accuracy: 0.9710\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0462 - accuracy: 0.9534\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0370 - accuracy: 0.9798\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0382 - accuracy: 0.9656\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0271 - accuracy: 0.9845\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 469us/step - loss: 0.0288 - accuracy: 0.9828\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0532 - accuracy: 0.9479\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0548 - accuracy: 0.9502\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0297 - accuracy: 0.9833\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0253 - accuracy: 0.9888\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0497 - accuracy: 0.9233\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0307 - accuracy: 0.9807\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0306 - accuracy: 0.9743\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 476us/step - loss: 0.0259 - accuracy: 0.9758\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0430 - accuracy: 0.9595\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0333 - accuracy: 0.9807\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0295 - accuracy: 0.9837\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0330 - accuracy: 0.9673\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0392 - accuracy: 0.9422\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 512us/step - loss: 0.0181 - accuracy: 0.9946\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 511us/step - loss: 0.0253 - accuracy: 0.9788\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0409 - accuracy: 0.9531\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0143 - accuracy: 0.9934\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0213 - accuracy: 0.9800\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 488us/step - loss: 0.0323 - accuracy: 0.9724\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0231 - accuracy: 0.9694\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0361 - accuracy: 0.9593\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 480us/step - loss: 0.0323 - accuracy: 0.9828\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 477us/step - loss: 0.0224 - accuracy: 0.9740\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0258 - accuracy: 0.9793\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 476us/step - loss: 0.0209 - accuracy: 0.9891\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 486us/step - loss: 0.0333 - accuracy: 0.9606\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x00000230C248AE50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1825 - accuracy: 0.7619\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 0s 590us/step - loss: 0.2569 - accuracy: 0.5520\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.2448 - accuracy: 0.5346\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.2363 - accuracy: 0.5435\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.2237 - accuracy: 0.6494\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.2227 - accuracy: 0.6963\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.2224 - accuracy: 0.6770\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.2047 - accuracy: 0.7410\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.2068 - accuracy: 0.7328\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.1898 - accuracy: 0.7505\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.1940 - accuracy: 0.8064\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.1995 - accuracy: 0.6866\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.1647 - accuracy: 0.7694\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.1748 - accuracy: 0.7738\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 431us/step - loss: 0.1670 - accuracy: 0.8164\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.1697 - accuracy: 0.8026\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.1653 - accuracy: 0.7567\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.1618 - accuracy: 0.7632\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.1450 - accuracy: 0.8111\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.1448 - accuracy: 0.8595\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.1278 - accuracy: 0.8574\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.1580 - accuracy: 0.7519\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.1414 - accuracy: 0.8074\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 466us/step - loss: 0.1338 - accuracy: 0.8366\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.1405 - accuracy: 0.8321\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.1171 - accuracy: 0.8521\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.1298 - accuracy: 0.8062\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 472us/step - loss: 0.1256 - accuracy: 0.8385\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.1142 - accuracy: 0.8666\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.1173 - accuracy: 0.8483\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 466us/step - loss: 0.1104 - accuracy: 0.8506\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.1105 - accuracy: 0.8553\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.1137 - accuracy: 0.8576\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.1051 - accuracy: 0.8782\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 477us/step - loss: 0.1000 - accuracy: 0.8940\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 459us/step - loss: 0.1043 - accuracy: 0.8689\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0819 - accuracy: 0.9141\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0896 - accuracy: 0.8927\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.1000 - accuracy: 0.8527\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.1063 - accuracy: 0.8455\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0918 - accuracy: 0.8991\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.1007 - accuracy: 0.8890\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0810 - accuracy: 0.9238\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0843 - accuracy: 0.8895\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 459us/step - loss: 0.0832 - accuracy: 0.9214\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 507us/step - loss: 0.0796 - accuracy: 0.9279\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0862 - accuracy: 0.8898\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0745 - accuracy: 0.9196\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0903 - accuracy: 0.9056\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0575 - accuracy: 0.9475\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 466us/step - loss: 0.0779 - accuracy: 0.8864\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 551us/step - loss: 0.0636 - accuracy: 0.9174\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 519us/step - loss: 0.0798 - accuracy: 0.8927\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 498us/step - loss: 0.0659 - accuracy: 0.9387\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0678 - accuracy: 0.9578\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0667 - accuracy: 0.9386\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0584 - accuracy: 0.9575\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0509 - accuracy: 0.9489\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 473us/step - loss: 0.0561 - accuracy: 0.9579\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 480us/step - loss: 0.0763 - accuracy: 0.9160\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0612 - accuracy: 0.9358\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0559 - accuracy: 0.9489\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 493us/step - loss: 0.0514 - accuracy: 0.9759\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 469us/step - loss: 0.0587 - accuracy: 0.9271\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 481us/step - loss: 0.0450 - accuracy: 0.9618\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 485us/step - loss: 0.0610 - accuracy: 0.9397\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 481us/step - loss: 0.0437 - accuracy: 0.9560\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 512us/step - loss: 0.0676 - accuracy: 0.9177\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 443us/step - loss: 0.0516 - accuracy: 0.9525\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 505us/step - loss: 0.0333 - accuracy: 0.9788\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 452us/step - loss: 0.0440 - accuracy: 0.9532\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0337 - accuracy: 0.9716\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 458us/step - loss: 0.0489 - accuracy: 0.9657\n",
      "Epoch 73/100\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0172 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-d3f16c6dd0b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m                   \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                   metrics=['accuracy'])\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[0mk_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"%.4f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\users\\ad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "# seed 값 설정\n",
    "seed = 0\n",
    "numpy.random.seed(seed)\n",
    "tf.random.set_seed(3)\n",
    "df = pd.read_csv('sonar.csv', header=None)\n",
    "dataset = df.values\n",
    "X = dataset[:,0:60].astype('float')\n",
    "Y_obj = dataset[:,60]\n",
    "e = LabelEncoder()\n",
    "e.fit(Y_obj)\n",
    "Y = e.transform(Y_obj)\n",
    "# 10개의 파일로 쪼갬\n",
    "n_fold = 10\n",
    "skf = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)\n",
    "# 빈 accuracy 배열\n",
    "accuracy = []\n",
    "# 모델의 설정, 컴파일, 실행\n",
    "for train, test in skf.split(X, Y):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(24, input_dim=60, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(X[train], Y[train], epochs=100, batch_size=5)\n",
    "    k_accuracy = \"%.4f\" % (model.evaluate(X[test], Y[test])[1])\n",
    "    accuracy.append(k_accuracy)\n",
    "# # 결과 출력\n",
    "# print(\"\\n %.f fold accuracy:\" % n_fold, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495fd97f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
