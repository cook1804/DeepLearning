{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "58ca2e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "df= pd.read_csv('creditcard.csv')\n",
    "df1= pd.read_csv('creditcard.csv')\n",
    "df.drop(['Time'], axis = 1, inplace =True)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fec41b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>4.356170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>-0.350151</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>-0.975926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>-0.254117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>-0.484782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>-0.081839</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>-0.399126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>-0.313249</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>-0.915427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>0.514355</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               V1         V2        V3        V4        V5        V6  \\\n",
       "0       -1.359807  -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1        1.191857   0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2       -1.358354  -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3       -0.966272  -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4       -1.158233   0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "...           ...        ...       ...       ...       ...       ...   \n",
       "284802 -11.881118  10.071785 -9.834783 -2.066656 -5.364473 -2.606837   \n",
       "284803  -0.732789  -0.055080  2.035030 -0.738589  0.868229  1.058415   \n",
       "284804   1.919565  -0.301254 -3.249640 -0.557828  2.630515  3.031260   \n",
       "284805  -0.240440   0.530483  0.702510  0.689799 -0.377961  0.623708   \n",
       "284806  -0.533413  -0.189733  0.703337 -0.506271 -0.012546 -0.649617   \n",
       "\n",
       "              V7        V8        V9       V10  ...       V21       V22  \\\n",
       "0       0.239599  0.098698  0.363787  0.090794  ... -0.018307  0.277838   \n",
       "1      -0.078803  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672   \n",
       "2       0.791461  0.247676 -1.514654  0.207643  ...  0.247998  0.771679   \n",
       "3       0.237609  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274   \n",
       "4       0.592941 -0.270533  0.817739  0.753074  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -4.918215  7.305334  1.914428  4.356170  ...  0.213454  0.111864   \n",
       "284803  0.024330  0.294869  0.584800 -0.975926  ...  0.214205  0.924384   \n",
       "284804 -0.296827  0.708417  0.432454 -0.484782  ...  0.232045  0.578229   \n",
       "284805 -0.686180  0.679145  0.392087 -0.399126  ...  0.265245  0.800049   \n",
       "284806  1.577006 -0.414650  0.486180 -0.915427  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28    Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  0.244964   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724 -0.342475   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  1.160686   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  0.140534   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153 -0.073403   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731 -0.350151   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527 -0.254117   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561 -0.081839   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533 -0.313249   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  0.514355   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 30 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# StanderScaler로 정규화\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 정규화한 Amount 값을 reshape해서 치환\n",
    "df[['Amount']] = scaler.fit_transform(df[['Amount']].values.reshape(-1,1))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5b843088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "\n",
    "X = df.values[:,0:29]\n",
    "Y = df.values[:,29]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size= 0.15, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8ed6a15d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1211/1211 [==============================] - 1s 563us/step - loss: 0.0897 - accuracy: 0.9865\n",
      "Epoch 2/100\n",
      "1211/1211 [==============================] - 1s 564us/step - loss: 0.0036 - accuracy: 0.9994\n",
      "Epoch 3/100\n",
      "1211/1211 [==============================] - 1s 562us/step - loss: 0.0028 - accuracy: 0.9994\n",
      "Epoch 4/100\n",
      "1211/1211 [==============================] - 1s 561us/step - loss: 0.0025 - accuracy: 0.9994\n",
      "Epoch 5/100\n",
      "1211/1211 [==============================] - 1s 564us/step - loss: 0.0023 - accuracy: 0.9995\n",
      "Epoch 6/100\n",
      "1211/1211 [==============================] - 1s 573us/step - loss: 0.0024 - accuracy: 0.9994\n",
      "Epoch 7/100\n",
      "1211/1211 [==============================] - 1s 560us/step - loss: 0.0022 - accuracy: 0.9995\n",
      "Epoch 8/100\n",
      "1211/1211 [==============================] - 1s 564us/step - loss: 0.0022 - accuracy: 0.99950s - loss: 0.0021 - accura\n",
      "Epoch 9/100\n",
      "1211/1211 [==============================] - 1s 570us/step - loss: 0.0019 - accuracy: 0.9996\n",
      "Epoch 10/100\n",
      "1211/1211 [==============================] - 1s 562us/step - loss: 0.0021 - accuracy: 0.9995\n",
      "Epoch 11/100\n",
      "1211/1211 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.99 - 1s 580us/step - loss: 0.0024 - accuracy: 0.9994\n",
      "Epoch 12/100\n",
      "1211/1211 [==============================] - 1s 600us/step - loss: 0.0020 - accuracy: 0.9995\n",
      "Epoch 13/100\n",
      "1211/1211 [==============================] - 1s 590us/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 14/100\n",
      "1211/1211 [==============================] - 1s 576us/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 15/100\n",
      "1211/1211 [==============================] - 1s 576us/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 16/100\n",
      "1211/1211 [==============================] - 1s 564us/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 17/100\n",
      "1211/1211 [==============================] - 1s 570us/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 18/100\n",
      "1211/1211 [==============================] - 1s 560us/step - loss: 0.0018 - accuracy: 0.9996\n",
      "Epoch 19/100\n",
      "1211/1211 [==============================] - 1s 563us/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 20/100\n",
      "1211/1211 [==============================] - 1s 563us/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 21/100\n",
      "1211/1211 [==============================] - 1s 562us/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 22/100\n",
      "1211/1211 [==============================] - 1s 566us/step - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 23/100\n",
      "1211/1211 [==============================] - 1s 576us/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 24/100\n",
      "1211/1211 [==============================] - 1s 575us/step - loss: 0.0013 - accuracy: 0.99970s - loss: 0.0013 - ac\n",
      "Epoch 25/100\n",
      "1211/1211 [==============================] - 1s 608us/step - loss: 0.0013 - accuracy: 0.99970s - loss: 0.0013 - accuracy: \n",
      "Epoch 26/100\n",
      "1211/1211 [==============================] - 1s 586us/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 27/100\n",
      "1211/1211 [==============================] - 1s 590us/step - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 28/100\n",
      "1211/1211 [==============================] - 1s 580us/step - loss: 0.0012 - accuracy: 0.9996\n",
      "Epoch 29/100\n",
      "1211/1211 [==============================] - 1s 572us/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 30/100\n",
      "1211/1211 [==============================] - 1s 582us/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 31/100\n",
      "1211/1211 [==============================] - 1s 560us/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 32/100\n",
      "1211/1211 [==============================] - 1s 561us/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 33/100\n",
      "1211/1211 [==============================] - 1s 567us/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 34/100\n",
      "1211/1211 [==============================] - 1s 559us/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 35/100\n",
      "1211/1211 [==============================] - 1s 567us/step - loss: 0.0010 - accuracy: 0.9997\n",
      "Epoch 36/100\n",
      "1211/1211 [==============================] - 1s 564us/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 37/100\n",
      "1211/1211 [==============================] - 1s 577us/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 38/100\n",
      "1211/1211 [==============================] - 1s 582us/step - loss: 8.2642e-04 - accuracy: 0.9998\n",
      "Epoch 39/100\n",
      "1211/1211 [==============================] - 1s 573us/step - loss: 8.5140e-04 - accuracy: 0.9998\n",
      "Epoch 40/100\n",
      "1211/1211 [==============================] - 1s 574us/step - loss: 9.9361e-04 - accuracy: 0.9997\n",
      "Epoch 41/100\n",
      "1211/1211 [==============================] - 1s 601us/step - loss: 6.8494e-04 - accuracy: 0.9998\n",
      "Epoch 42/100\n",
      "1211/1211 [==============================] - 1s 573us/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 43/100\n",
      "1211/1211 [==============================] - 1s 565us/step - loss: 9.3619e-04 - accuracy: 0.9998\n",
      "Epoch 44/100\n",
      "1211/1211 [==============================] - 1s 581us/step - loss: 8.7609e-04 - accuracy: 0.9998\n",
      "Epoch 45/100\n",
      "1211/1211 [==============================] - 1s 572us/step - loss: 8.4484e-04 - accuracy: 0.9998\n",
      "Epoch 46/100\n",
      "1211/1211 [==============================] - 1s 588us/step - loss: 8.5948e-04 - accuracy: 0.9997\n",
      "Epoch 47/100\n",
      "1211/1211 [==============================] - 1s 574us/step - loss: 7.3544e-04 - accuracy: 0.9998\n",
      "Epoch 48/100\n",
      "1211/1211 [==============================] - 1s 571us/step - loss: 7.3230e-04 - accuracy: 0.9998\n",
      "Epoch 49/100\n",
      "1211/1211 [==============================] - 1s 578us/step - loss: 8.8372e-04 - accuracy: 0.9998\n",
      "Epoch 50/100\n",
      "1211/1211 [==============================] - 1s 574us/step - loss: 7.9870e-04 - accuracy: 0.9998\n",
      "Epoch 51/100\n",
      "1211/1211 [==============================] - 1s 578us/step - loss: 7.2444e-04 - accuracy: 0.9998\n",
      "Epoch 52/100\n",
      "1211/1211 [==============================] - 1s 577us/step - loss: 7.3343e-04 - accuracy: 0.9998\n",
      "Epoch 53/100\n",
      "1211/1211 [==============================] - 1s 572us/step - loss: 8.6517e-04 - accuracy: 0.9998\n",
      "Epoch 54/100\n",
      "1211/1211 [==============================] - 1s 571us/step - loss: 6.5552e-04 - accuracy: 0.9998\n",
      "Epoch 55/100\n",
      "1211/1211 [==============================] - 1s 589us/step - loss: 6.7305e-04 - accuracy: 0.9998\n",
      "Epoch 56/100\n",
      "1211/1211 [==============================] - 1s 585us/step - loss: 5.8702e-04 - accuracy: 0.9998\n",
      "Epoch 57/100\n",
      "1211/1211 [==============================] - 1s 572us/step - loss: 0.0010 - accuracy: 0.9997\n",
      "Epoch 58/100\n",
      "1211/1211 [==============================] - 1s 568us/step - loss: 7.5753e-04 - accuracy: 0.9998\n",
      "Epoch 59/100\n",
      "1211/1211 [==============================] - 1s 574us/step - loss: 6.5678e-04 - accuracy: 0.9998\n",
      "Epoch 60/100\n",
      "1211/1211 [==============================] - 1s 581us/step - loss: 6.2381e-04 - accuracy: 0.9998\n",
      "Epoch 61/100\n",
      "1211/1211 [==============================] - 1s 573us/step - loss: 5.9687e-04 - accuracy: 0.9998\n",
      "Epoch 62/100\n",
      "1211/1211 [==============================] - 1s 575us/step - loss: 6.5956e-04 - accuracy: 0.9998\n",
      "Epoch 63/100\n",
      "1211/1211 [==============================] - 1s 569us/step - loss: 6.6238e-04 - accuracy: 0.9998\n",
      "Epoch 64/100\n",
      "1211/1211 [==============================] - 1s 569us/step - loss: 4.1426e-04 - accuracy: 0.9999\n",
      "Epoch 65/100\n",
      "1211/1211 [==============================] - 1s 568us/step - loss: 5.0776e-04 - accuracy: 0.9999\n",
      "Epoch 66/100\n",
      "1211/1211 [==============================] - 1s 576us/step - loss: 5.6384e-04 - accuracy: 0.9998\n",
      "Epoch 67/100\n",
      "1211/1211 [==============================] - 1s 572us/step - loss: 6.0836e-04 - accuracy: 0.9998\n",
      "Epoch 68/100\n",
      "1211/1211 [==============================] - 1s 576us/step - loss: 5.7657e-04 - accuracy: 0.99990s - loss: 5.5896e-04 - accu\n",
      "Epoch 69/100\n",
      "1211/1211 [==============================] - 1s 590us/step - loss: 5.2622e-04 - accuracy: 0.9998\n",
      "Epoch 70/100\n",
      "1211/1211 [==============================] - 1s 584us/step - loss: 4.7871e-04 - accuracy: 0.9999\n",
      "Epoch 71/100\n",
      "1211/1211 [==============================] - 1s 587us/step - loss: 4.7544e-04 - accuracy: 0.9999\n",
      "Epoch 72/100\n",
      "1211/1211 [==============================] - 1s 571us/step - loss: 5.3595e-04 - accuracy: 0.9999\n",
      "Epoch 73/100\n",
      "1211/1211 [==============================] - 1s 570us/step - loss: 4.3299e-04 - accuracy: 0.9999\n",
      "Epoch 74/100\n",
      "1211/1211 [==============================] - 1s 580us/step - loss: 6.3169e-04 - accuracy: 0.9998\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1211/1211 [==============================] - 1s 568us/step - loss: 6.8679e-04 - accuracy: 0.9998\n",
      "Epoch 76/100\n",
      "1211/1211 [==============================] - 1s 568us/step - loss: 3.2910e-04 - accuracy: 0.9999\n",
      "Epoch 77/100\n",
      "1211/1211 [==============================] - 1s 565us/step - loss: 4.7821e-04 - accuracy: 0.9999\n",
      "Epoch 78/100\n",
      "1211/1211 [==============================] - 1s 579us/step - loss: 3.8118e-04 - accuracy: 0.9999\n",
      "Epoch 79/100\n",
      "1211/1211 [==============================] - 1s 575us/step - loss: 4.9510e-04 - accuracy: 0.9999\n",
      "Epoch 80/100\n",
      "1211/1211 [==============================] - 1s 569us/step - loss: 4.6911e-04 - accuracy: 0.9999\n",
      "Epoch 81/100\n",
      "1211/1211 [==============================] - 1s 574us/step - loss: 4.2477e-04 - accuracy: 0.9999\n",
      "Epoch 82/100\n",
      "1211/1211 [==============================] - 1s 564us/step - loss: 4.9685e-04 - accuracy: 0.9998\n",
      "Epoch 83/100\n",
      "1211/1211 [==============================] - 1s 564us/step - loss: 4.0131e-04 - accuracy: 0.9999\n",
      "Epoch 84/100\n",
      "1211/1211 [==============================] - 1s 578us/step - loss: 3.5861e-04 - accuracy: 0.9999\n",
      "Epoch 85/100\n",
      "1211/1211 [==============================] - 1s 576us/step - loss: 5.3436e-04 - accuracy: 0.9999\n",
      "Epoch 86/100\n",
      "1211/1211 [==============================] - 1s 570us/step - loss: 4.6928e-04 - accuracy: 0.9998\n",
      "Epoch 87/100\n",
      "1211/1211 [==============================] - 1s 569us/step - loss: 3.7449e-04 - accuracy: 0.99990s - loss: 2.1155e\n",
      "Epoch 88/100\n",
      "1211/1211 [==============================] - 1s 566us/step - loss: 3.6622e-04 - accuracy: 0.9999\n",
      "Epoch 89/100\n",
      "1211/1211 [==============================] - 1s 569us/step - loss: 3.9243e-04 - accuracy: 0.99990s - loss: 3.8460e-04 - accuracy: \n",
      "Epoch 90/100\n",
      "1211/1211 [==============================] - 1s 592us/step - loss: 4.4831e-04 - accuracy: 0.9999\n",
      "Epoch 91/100\n",
      "1211/1211 [==============================] - 1s 595us/step - loss: 3.4237e-04 - accuracy: 0.9999\n",
      "Epoch 92/100\n",
      "1211/1211 [==============================] - 1s 569us/step - loss: 3.6411e-04 - accuracy: 0.9999\n",
      "Epoch 93/100\n",
      "1211/1211 [==============================] - 1s 568us/step - loss: 3.2044e-04 - accuracy: 0.9999\n",
      "Epoch 94/100\n",
      "1211/1211 [==============================] - 1s 585us/step - loss: 3.4423e-04 - accuracy: 0.9999\n",
      "Epoch 95/100\n",
      "1211/1211 [==============================] - 1s 584us/step - loss: 3.0965e-04 - accuracy: 0.9999\n",
      "Epoch 96/100\n",
      "1211/1211 [==============================] - 1s 568us/step - loss: 3.4882e-04 - accuracy: 0.9999\n",
      "Epoch 97/100\n",
      "1211/1211 [==============================] - 1s 579us/step - loss: 4.1183e-04 - accuracy: 0.99990s - loss: 3.8151e-04 - ac\n",
      "Epoch 98/100\n",
      "1211/1211 [==============================] - 1s 573us/step - loss: 3.1880e-04 - accuracy: 0.9999\n",
      "Epoch 99/100\n",
      "1211/1211 [==============================] - 1s 571us/step - loss: 3.2224e-04 - accuracy: 0.9999\n",
      "Epoch 100/100\n",
      "1211/1211 [==============================] - 1s 573us/step - loss: 3.8052e-04 - accuracy: 0.9999\n",
      "1336/1336 [==============================] - 1s 400us/step - loss: 0.0066 - accuracy: 0.9993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.006588366813957691, 0.9992743730545044]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 모델생성 0 : 활성화 함수 relu, sigmoid를 이용한 ANN 모델링\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(64, activation=\"relu\", input_dim=(X_train.shape[1])))\n",
    "model.add(tf.keras.layers.Dense(1, activation ='sigmoid'))\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train, epochs = 100, batch_size=200, verbose=1)\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.legend(['accuracy'])\n",
    "\n",
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75c8c2f",
   "metadata": {},
   "source": [
    "### DNN 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b2299ce6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "12105/12105 [==============================] - 6s 490us/step - loss: 0.0496 - accuracy: 0.9916\n",
      "Epoch 2/150\n",
      "12105/12105 [==============================] - 6s 498us/step - loss: 0.0032 - accuracy: 0.9994\n",
      "Epoch 3/150\n",
      " 8433/12105 [===================>..........] - ETA: 1s - loss: 0.0027 - accuracy: 0.9994"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-03f8b05a4336>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\ad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\users\\ad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 모델생성 1 : 활성화 함수 relu, softmax\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(30, activation=\"relu\", input_dim=(X_train.shape[1])))\n",
    "model.add(tf.keras.layers.Dense(52, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation ='softmax'))\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, epochs = 150, batch_size=20, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f7ab08e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1211/1211 [==============================] - 1s 619us/step - loss: 0.0460 - accuracy: 0.9986\n",
      "Epoch 2/1000\n",
      "1211/1211 [==============================] - 1s 596us/step - loss: 0.0033 - accuracy: 0.9994\n",
      "Epoch 3/1000\n",
      "1211/1211 [==============================] - 1s 599us/step - loss: 0.0027 - accuracy: 0.9994\n",
      "Epoch 4/1000\n",
      "1211/1211 [==============================] - 1s 614us/step - loss: 0.0024 - accuracy: 0.9994\n",
      "Epoch 5/1000\n",
      "1211/1211 [==============================] - 1s 614us/step - loss: 0.0022 - accuracy: 0.9995\n",
      "Epoch 6/1000\n",
      "1211/1211 [==============================] - 1s 617us/step - loss: 0.0022 - accuracy: 0.9994\n",
      "Epoch 7/1000\n",
      "1211/1211 [==============================] - 1s 617us/step - loss: 0.0021 - accuracy: 0.9995\n",
      "Epoch 8/1000\n",
      "1211/1211 [==============================] - 1s 611us/step - loss: 0.0021 - accuracy: 0.9995\n",
      "Epoch 9/1000\n",
      "1211/1211 [==============================] - 1s 591us/step - loss: 0.0018 - accuracy: 0.9996\n",
      "Epoch 10/1000\n",
      "1211/1211 [==============================] - 1s 590us/step - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 11/1000\n",
      "1211/1211 [==============================] - 1s 603us/step - loss: 0.0021 - accuracy: 0.9995\n",
      "Epoch 12/1000\n",
      "1211/1211 [==============================] - 1s 621us/step - loss: 0.0018 - accuracy: 0.9995\n",
      "Epoch 13/1000\n",
      "1211/1211 [==============================] - 1s 600us/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 14/1000\n",
      "1211/1211 [==============================] - 1s 602us/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 15/1000\n",
      "1211/1211 [==============================] - 1s 600us/step - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 16/1000\n",
      "1211/1211 [==============================] - 1s 593us/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 17/1000\n",
      "1211/1211 [==============================] - 1s 617us/step - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 18/1000\n",
      "1211/1211 [==============================] - 1s 590us/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 19/1000\n",
      " 275/1211 [=====>........................] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-11eacef3774d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\ad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\users\\ad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 모델생성 2 : 활성화 함수 relu, sigmoid\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(30, activation=\"relu\", input_dim=(X_train.shape[1])))\n",
    "model.add(tf.keras.layers.Dense(52, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation ='sigmoid'))\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, epochs = 1000, batch_size=200, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8090243e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1211/1211 [==============================] - 1s 658us/step - loss: 0.0778 - accuracy: 0.9711\n",
      "Epoch 2/1000\n",
      "1211/1211 [==============================] - 1s 646us/step - loss: 0.0031 - accuracy: 0.9994\n",
      "Epoch 3/1000\n",
      "1211/1211 [==============================] - 1s 640us/step - loss: 0.0025 - accuracy: 0.9994\n",
      "Epoch 4/1000\n",
      "1211/1211 [==============================] - 1s 639us/step - loss: 0.0023 - accuracy: 0.9994\n",
      "Epoch 5/1000\n",
      "1211/1211 [==============================] - 1s 641us/step - loss: 0.0021 - accuracy: 0.9995\n",
      "Epoch 6/1000\n",
      "1211/1211 [==============================] - 1s 644us/step - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 7/1000\n",
      "1211/1211 [==============================] - 1s 659us/step - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 8/1000\n",
      "1211/1211 [==============================] - 1s 679us/step - loss: 0.0020 - accuracy: 0.9995\n",
      "Epoch 9/1000\n",
      "1211/1211 [==============================] - 1s 640us/step - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 10/1000\n",
      "1211/1211 [==============================] - 1s 638us/step - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 11/1000\n",
      "1211/1211 [==============================] - 1s 640us/step - loss: 0.0020 - accuracy: 0.9995\n",
      "Epoch 12/1000\n",
      "1211/1211 [==============================] - 1s 642us/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 13/1000\n",
      "1211/1211 [==============================] - 1s 639us/step - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 14/1000\n",
      "1211/1211 [==============================] - 1s 639us/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 15/1000\n",
      "1211/1211 [==============================] - 1s 646us/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 16/1000\n",
      "1211/1211 [==============================] - 1s 644us/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 17/1000\n",
      "1211/1211 [==============================] - 1s 659us/step - loss: 0.0012 - accuracy: 0.9996\n",
      "Epoch 18/1000\n",
      "1211/1211 [==============================] - 1s 659us/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 19/1000\n",
      "1211/1211 [==============================] - 1s 638us/step - loss: 9.0039e-04 - accuracy: 0.9997\n",
      "Epoch 20/1000\n",
      "1211/1211 [==============================] - 1s 647us/step - loss: 9.7579e-04 - accuracy: 0.9997\n",
      "Epoch 21/1000\n",
      "1211/1211 [==============================] - 1s 648us/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 22/1000\n",
      "1211/1211 [==============================] - 1s 666us/step - loss: 8.6153e-04 - accuracy: 0.9998\n",
      "Epoch 23/1000\n",
      "1211/1211 [==============================] - 1s 657us/step - loss: 6.6966e-04 - accuracy: 0.9998\n",
      "Epoch 24/1000\n",
      " 394/1211 [========>.....................] - ETA: 0s - loss: 6.4799e-04 - accuracy: 0.9998"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-e8f167278320>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\ad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\users\\ad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 모델생성 3 : 활성화 함수 relu, sigmoid 은닉층 추가\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(64, activation=\"relu\", input_dim=(X_train.shape[1])))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation ='sigmoid'))\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, epochs = 1000, batch_size=200, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2521fe11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1211/1211 [==============================] - 1s 721us/step - loss: 0.1088 - accuracy: 0.9837\n",
      "Epoch 2/1000\n",
      "1211/1211 [==============================] - 1s 698us/step - loss: 0.0032 - accuracy: 0.9994\n",
      "Epoch 3/1000\n",
      "1211/1211 [==============================] - 1s 697us/step - loss: 0.0028 - accuracy: 0.9994\n",
      "Epoch 4/1000\n",
      "1211/1211 [==============================] - 1s 712us/step - loss: 0.0024 - accuracy: 0.9994\n",
      "Epoch 5/1000\n",
      "1211/1211 [==============================] - 1s 718us/step - loss: 0.0023 - accuracy: 0.9995\n",
      "Epoch 6/1000\n",
      " 428/1211 [=========>....................] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-dc5b1634d5af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\ad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\users\\ad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 모델생성 3 : 활성화 함수 relu, sigmoid  은닉층 두 개 추가\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(64, activation=\"relu\", input_dim=(X_train.shape[1])))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(4, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation ='sigmoid'))\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, epochs = 1000, batch_size=200, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "770cdc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1211/1211 [==============================] - 1s 659us/step - loss: 0.0545 - accuracy: 0.9919\n",
      "Epoch 2/100\n",
      "1211/1211 [==============================] - 1s 626us/step - loss: 0.0030 - accuracy: 0.9994\n",
      "Epoch 3/100\n",
      "1211/1211 [==============================] - 1s 631us/step - loss: 0.0026 - accuracy: 0.9994\n",
      "Epoch 4/100\n",
      "1211/1211 [==============================] - 1s 624us/step - loss: 0.0023 - accuracy: 0.9994\n",
      "Epoch 5/100\n",
      "1211/1211 [==============================] - 1s 611us/step - loss: 0.0021 - accuracy: 0.9995\n",
      "Epoch 6/100\n",
      "1211/1211 [==============================] - 1s 633us/step - loss: 0.0020 - accuracy: 0.9995\n",
      "Epoch 7/100\n",
      "1211/1211 [==============================] - 1s 640us/step - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 8/100\n",
      "1211/1211 [==============================] - 1s 636us/step - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 9/100\n",
      "1211/1211 [==============================] - 1s 646us/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 10/100\n",
      "1211/1211 [==============================] - 1s 638us/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 11/100\n",
      "1211/1211 [==============================] - 1s 627us/step - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 12/100\n",
      "1211/1211 [==============================] - 1s 623us/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 13/100\n",
      "1211/1211 [==============================] - 1s 647us/step - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 14/100\n",
      "1211/1211 [==============================] - 1s 669us/step - loss: 0.0012 - accuracy: 0.9996\n",
      "Epoch 15/100\n",
      "1211/1211 [==============================] - 1s 662us/step - loss: 9.6614e-04 - accuracy: 0.9997\n",
      "Epoch 16/100\n",
      "1211/1211 [==============================] - 1s 677us/step - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 17/100\n",
      "1211/1211 [==============================] - 1s 657us/step - loss: 0.0012 - accuracy: 0.9996\n",
      "Epoch 18/100\n",
      "1211/1211 [==============================] - 1s 663us/step - loss: 0.0010 - accuracy: 0.9997\n",
      "Epoch 19/100\n",
      "1211/1211 [==============================] - 1s 664us/step - loss: 9.6996e-04 - accuracy: 0.9997\n",
      "Epoch 20/100\n",
      "1211/1211 [==============================] - 1s 695us/step - loss: 7.9112e-04 - accuracy: 0.9998\n",
      "Epoch 21/100\n",
      "1211/1211 [==============================] - 1s 659us/step - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 22/100\n",
      "1211/1211 [==============================] - 1s 626us/step - loss: 8.5262e-04 - accuracy: 0.9997\n",
      "Epoch 23/100\n",
      "1211/1211 [==============================] - 1s 652us/step - loss: 6.5581e-04 - accuracy: 0.9998\n",
      "Epoch 24/100\n",
      "1211/1211 [==============================] - 1s 685us/step - loss: 5.8229e-04 - accuracy: 0.9998\n",
      "Epoch 25/100\n",
      "1211/1211 [==============================] - 1s 689us/step - loss: 9.1718e-04 - accuracy: 0.9997\n",
      "Epoch 26/100\n",
      "1211/1211 [==============================] - 1s 699us/step - loss: 6.0580e-04 - accuracy: 0.99980s - loss: 6.0385e-04 - accuracy: 0.99\n",
      "Epoch 27/100\n",
      "1211/1211 [==============================] - 1s 651us/step - loss: 6.0579e-04 - accuracy: 0.9998\n",
      "Epoch 28/100\n",
      "1211/1211 [==============================] - 1s 645us/step - loss: 7.7227e-04 - accuracy: 0.9997\n",
      "Epoch 29/100\n",
      "1211/1211 [==============================] - 1s 691us/step - loss: 4.9004e-04 - accuracy: 0.99980s - loss: 4.6352e-04 - accu\n",
      "Epoch 30/100\n",
      "1211/1211 [==============================] - 1s 670us/step - loss: 5.2298e-04 - accuracy: 0.9998\n",
      "Epoch 31/100\n",
      "1211/1211 [==============================] - 1s 675us/step - loss: 5.3040e-04 - accuracy: 0.9998\n",
      "Epoch 32/100\n",
      "1211/1211 [==============================] - 1s 700us/step - loss: 8.7663e-04 - accuracy: 0.9997\n",
      "Epoch 33/100\n",
      "1211/1211 [==============================] - 1s 666us/step - loss: 5.0188e-04 - accuracy: 0.9998\n",
      "Epoch 34/100\n",
      "1211/1211 [==============================] - 1s 655us/step - loss: 4.7165e-04 - accuracy: 0.9998\n",
      "Epoch 35/100\n",
      "1211/1211 [==============================] - 1s 776us/step - loss: 5.0148e-04 - accuracy: 0.99990s - loss: 4.8336e-0\n",
      "Epoch 36/100\n",
      "1211/1211 [==============================] - 1s 638us/step - loss: 6.0597e-04 - accuracy: 0.9998\n",
      "Epoch 37/100\n",
      "1211/1211 [==============================] - 1s 690us/step - loss: 5.8366e-04 - accuracy: 0.9998\n",
      "Epoch 38/100\n",
      "1211/1211 [==============================] - 1s 661us/step - loss: 3.4940e-04 - accuracy: 0.9999\n",
      "Epoch 39/100\n",
      "1211/1211 [==============================] - 1s 677us/step - loss: 4.3639e-04 - accuracy: 0.9998\n",
      "Epoch 40/100\n",
      "1211/1211 [==============================] - 1s 656us/step - loss: 7.0057e-04 - accuracy: 0.9997\n",
      "Epoch 41/100\n",
      "1211/1211 [==============================] - 1s 648us/step - loss: 2.9506e-04 - accuracy: 0.9999\n",
      "Epoch 42/100\n",
      "1211/1211 [==============================] - 1s 636us/step - loss: 4.6646e-04 - accuracy: 0.9998\n",
      "Epoch 43/100\n",
      "1211/1211 [==============================] - 1s 625us/step - loss: 5.7756e-04 - accuracy: 0.9998\n",
      "Epoch 44/100\n",
      "1211/1211 [==============================] - 1s 620us/step - loss: 4.5563e-04 - accuracy: 0.9998\n",
      "Epoch 45/100\n",
      "1211/1211 [==============================] - 1s 669us/step - loss: 6.3998e-04 - accuracy: 0.9998\n",
      "Epoch 46/100\n",
      "1211/1211 [==============================] - 1s 670us/step - loss: 3.2824e-04 - accuracy: 0.9999\n",
      "Epoch 47/100\n",
      "1211/1211 [==============================] - 1s 681us/step - loss: 5.1202e-04 - accuracy: 0.9998\n",
      "Epoch 48/100\n",
      "1211/1211 [==============================] - 1s 677us/step - loss: 4.3843e-04 - accuracy: 0.9998\n",
      "Epoch 49/100\n",
      "1211/1211 [==============================] - 1s 673us/step - loss: 6.3884e-04 - accuracy: 0.9997\n",
      "Epoch 50/100\n",
      "1211/1211 [==============================] - 1s 649us/step - loss: 3.3604e-04 - accuracy: 0.9999\n",
      "Epoch 51/100\n",
      "1211/1211 [==============================] - 1s 672us/step - loss: 3.2099e-04 - accuracy: 0.9999\n",
      "Epoch 52/100\n",
      "1211/1211 [==============================] - 1s 711us/step - loss: 4.4766e-04 - accuracy: 0.9998\n",
      "Epoch 53/100\n",
      "1211/1211 [==============================] - 1s 645us/step - loss: 5.3052e-04 - accuracy: 0.9998\n",
      "Epoch 54/100\n",
      "1211/1211 [==============================] - 1s 632us/step - loss: 2.9955e-04 - accuracy: 0.9999\n",
      "Epoch 55/100\n",
      "1211/1211 [==============================] - 1s 636us/step - loss: 2.7507e-04 - accuracy: 0.9999\n",
      "Epoch 56/100\n",
      "1211/1211 [==============================] - 1s 628us/step - loss: 4.6793e-04 - accuracy: 0.99980s - loss: 5.2928e-0\n",
      "Epoch 57/100\n",
      "1211/1211 [==============================] - 1s 637us/step - loss: 3.8979e-04 - accuracy: 0.9999\n",
      "Epoch 58/100\n",
      "1211/1211 [==============================] - 1s 637us/step - loss: 6.5798e-04 - accuracy: 0.9998\n",
      "Epoch 59/100\n",
      "1211/1211 [==============================] - 1s 635us/step - loss: 2.7022e-04 - accuracy: 0.9999\n",
      "Epoch 60/100\n",
      "1211/1211 [==============================] - 1s 633us/step - loss: 2.5804e-04 - accuracy: 0.9999\n",
      "Epoch 61/100\n",
      "1211/1211 [==============================] - 1s 634us/step - loss: 8.0431e-04 - accuracy: 0.9998\n",
      "Epoch 62/100\n",
      "1211/1211 [==============================] - 1s 643us/step - loss: 2.9773e-04 - accuracy: 0.9999\n",
      "Epoch 63/100\n",
      "1211/1211 [==============================] - 1s 651us/step - loss: 4.2506e-04 - accuracy: 0.9999\n",
      "Epoch 64/100\n",
      "1211/1211 [==============================] - 1s 623us/step - loss: 6.0138e-04 - accuracy: 0.9999\n",
      "Epoch 65/100\n",
      "1211/1211 [==============================] - 1s 628us/step - loss: 3.1337e-04 - accuracy: 0.9999\n",
      "Epoch 66/100\n",
      "1211/1211 [==============================] - 1s 656us/step - loss: 4.2034e-04 - accuracy: 0.9999\n",
      "Epoch 67/100\n",
      "1211/1211 [==============================] - 1s 764us/step - loss: 2.7476e-04 - accuracy: 0.9999\n",
      "Epoch 68/100\n",
      "1211/1211 [==============================] - 1s 643us/step - loss: 4.4727e-04 - accuracy: 0.9998\n",
      "Epoch 69/100\n",
      "1211/1211 [==============================] - 1s 624us/step - loss: 2.0037e-04 - accuracy: 0.9999\n",
      "Epoch 70/100\n",
      "1211/1211 [==============================] - 1s 637us/step - loss: 5.4729e-04 - accuracy: 0.9998\n",
      "Epoch 71/100\n",
      "1211/1211 [==============================] - 1s 634us/step - loss: 5.6405e-04 - accuracy: 0.9999\n",
      "Epoch 72/100\n",
      "1211/1211 [==============================] - 1s 700us/step - loss: 4.0069e-04 - accuracy: 0.9999\n",
      "Epoch 73/100\n",
      "1211/1211 [==============================] - 1s 760us/step - loss: 2.0731e-04 - accuracy: 0.9999\n",
      "Epoch 74/100\n",
      "1211/1211 [==============================] - 1s 708us/step - loss: 6.6999e-04 - accuracy: 0.9998\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1211/1211 [==============================] - 1s 693us/step - loss: 2.7101e-04 - accuracy: 0.9999\n",
      "Epoch 76/100\n",
      "1211/1211 [==============================] - 1s 687us/step - loss: 2.0510e-04 - accuracy: 0.9999\n",
      "Epoch 77/100\n",
      "1211/1211 [==============================] - 1s 666us/step - loss: 5.7737e-04 - accuracy: 0.99980s - loss: 6.6854e-0\n",
      "Epoch 78/100\n",
      "1211/1211 [==============================] - 1s 715us/step - loss: 2.2983e-04 - accuracy: 0.9999\n",
      "Epoch 79/100\n",
      "1211/1211 [==============================] - 1s 664us/step - loss: 4.9749e-04 - accuracy: 0.9999\n",
      "Epoch 80/100\n",
      "1211/1211 [==============================] - 1s 676us/step - loss: 5.2888e-04 - accuracy: 0.9998\n",
      "Epoch 81/100\n",
      "1211/1211 [==============================] - 1s 678us/step - loss: 1.8708e-04 - accuracy: 0.9999\n",
      "Epoch 82/100\n",
      "1211/1211 [==============================] - 1s 637us/step - loss: 3.5813e-04 - accuracy: 0.9999\n",
      "Epoch 83/100\n",
      "1211/1211 [==============================] - 1s 654us/step - loss: 2.6965e-04 - accuracy: 0.9999\n",
      "Epoch 84/100\n",
      "1211/1211 [==============================] - 1s 678us/step - loss: 2.0072e-04 - accuracy: 0.99990s - loss: 1.9966e-04 - accuracy: \n",
      "Epoch 85/100\n",
      "1211/1211 [==============================] - 1s 687us/step - loss: 2.8388e-04 - accuracy: 0.9999\n",
      "Epoch 86/100\n",
      "1211/1211 [==============================] - 1s 693us/step - loss: 3.1597e-04 - accuracy: 0.99990s - los\n",
      "Epoch 87/100\n",
      "1211/1211 [==============================] - 1s 677us/step - loss: 3.3512e-04 - accuracy: 0.9999\n",
      "Epoch 88/100\n",
      "1211/1211 [==============================] - 1s 649us/step - loss: 1.7864e-04 - accuracy: 0.9999\n",
      "Epoch 89/100\n",
      "1211/1211 [==============================] - 1s 674us/step - loss: 3.7447e-04 - accuracy: 0.9999\n",
      "Epoch 90/100\n",
      "1211/1211 [==============================] - 1s 642us/step - loss: 1.8225e-04 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1211/1211 [==============================] - 1s 763us/step - loss: 2.6364e-04 - accuracy: 0.9999\n",
      "Epoch 92/100\n",
      "1211/1211 [==============================] - 1s 683us/step - loss: 1.9985e-04 - accuracy: 0.9999\n",
      "Epoch 93/100\n",
      "1211/1211 [==============================] - 1s 690us/step - loss: 4.3893e-04 - accuracy: 0.99990s - loss: 5.1270e-04 \n",
      "Epoch 94/100\n",
      "1211/1211 [==============================] - 1s 679us/step - loss: 6.2203e-04 - accuracy: 0.9999\n",
      "Epoch 95/100\n",
      "1211/1211 [==============================] - 1s 663us/step - loss: 1.6981e-04 - accuracy: 0.99990s - loss: 1.5709e-04 - accura\n",
      "Epoch 96/100\n",
      "1211/1211 [==============================] - 1s 673us/step - loss: 3.2101e-04 - accuracy: 0.9999\n",
      "Epoch 97/100\n",
      "1211/1211 [==============================] - 1s 658us/step - loss: 3.0954e-04 - accuracy: 0.9999\n",
      "Epoch 98/100\n",
      "1211/1211 [==============================] - 1s 659us/step - loss: 2.2567e-04 - accuracy: 0.9999\n",
      "Epoch 99/100\n",
      "1211/1211 [==============================] - 1s 740us/step - loss: 4.4173e-04 - accuracy: 0.9999\n",
      "Epoch 100/100\n",
      "1211/1211 [==============================] - 1s 698us/step - loss: 2.2206e-04 - accuracy: 0.9999\n",
      "1336/1336 [==============================] - 1s 429us/step - loss: 0.0136 - accuracy: 0.9994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.013558890670537949, 0.9993914365768433]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 모델생성 3 : 활성화 함수 relu, sigmoid 은닉층 추가\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(64, activation=\"relu\", input_dim=(X_train.shape[1])))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation ='sigmoid'))\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train, epochs = 100, batch_size=200, verbose=1)\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.legend(['accuracy'])\n",
    "\n",
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3c8f0215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1211/1211 [==============================] - 1s 588us/step - loss: 0.0775 - accuracy: 0.9913\n",
      "Epoch 2/100\n",
      "1211/1211 [==============================] - 1s 569us/step - loss: 0.0032 - accuracy: 0.9994\n",
      "Epoch 3/100\n",
      "1211/1211 [==============================] - 1s 566us/step - loss: 0.0028 - accuracy: 0.9994\n",
      "Epoch 4/100\n",
      "1211/1211 [==============================] - 1s 588us/step - loss: 0.0025 - accuracy: 0.9994\n",
      "Epoch 5/100\n",
      "1211/1211 [==============================] - 1s 567us/step - loss: 0.0023 - accuracy: 0.9995\n",
      "Epoch 6/100\n",
      "1211/1211 [==============================] - 1s 568us/step - loss: 0.0023 - accuracy: 0.9994\n",
      "Epoch 7/100\n",
      "1211/1211 [==============================] - 1s 559us/step - loss: 0.0021 - accuracy: 0.9995\n",
      "Epoch 8/100\n",
      "1211/1211 [==============================] - 1s 579us/step - loss: 0.0021 - accuracy: 0.9995\n",
      "Epoch 9/100\n",
      "1211/1211 [==============================] - 1s 563us/step - loss: 0.0018 - accuracy: 0.9996\n",
      "Epoch 10/100\n",
      "1211/1211 [==============================] - 1s 596us/step - loss: 0.0020 - accuracy: 0.9995\n",
      "Epoch 11/100\n",
      "1211/1211 [==============================] - 1s 560us/step - loss: 0.0022 - accuracy: 0.9995\n",
      "Epoch 12/100\n",
      "1211/1211 [==============================] - 1s 569us/step - loss: 0.0020 - accuracy: 0.9996\n",
      "Epoch 13/100\n",
      "1211/1211 [==============================] - 1s 566us/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 14/100\n",
      "1211/1211 [==============================] - 1s 559us/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 15/100\n",
      "1211/1211 [==============================] - 1s 578us/step - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 16/100\n",
      "1211/1211 [==============================] - 1s 562us/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 17/100\n",
      "1211/1211 [==============================] - 1s 606us/step - loss: 0.0015 - accuracy: 0.9995\n",
      "Epoch 18/100\n",
      "1211/1211 [==============================] - 1s 561us/step - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 19/100\n",
      "1211/1211 [==============================] - 1s 578us/step - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 20/100\n",
      "1211/1211 [==============================] - 1s 579us/step - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 21/100\n",
      "1211/1211 [==============================] - 1s 601us/step - loss: 0.0015 - accuracy: 0.9997\n",
      "Epoch 22/100\n",
      "1211/1211 [==============================] - 1s 602us/step - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 23/100\n",
      "1211/1211 [==============================] - 1s 617us/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 24/100\n",
      "1211/1211 [==============================] - 1s 595us/step - loss: 0.0012 - accuracy: 0.99970s - loss: 0.0012 - accura\n",
      "Epoch 25/100\n",
      "1211/1211 [==============================] - 1s 619us/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 26/100\n",
      "1211/1211 [==============================] - 1s 600us/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 27/100\n",
      "1211/1211 [==============================] - 1s 618us/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 28/100\n",
      "1211/1211 [==============================] - 1s 598us/step - loss: 0.0012 - accuracy: 0.9996\n",
      "Epoch 29/100\n",
      "1211/1211 [==============================] - 1s 596us/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 30/100\n",
      "1211/1211 [==============================] - 1s 618us/step - loss: 9.8891e-04 - accuracy: 0.99980s - loss: 9.7236e-04 - accuracy: 0.\n",
      "Epoch 31/100\n",
      "1211/1211 [==============================] - 1s 620us/step - loss: 9.1198e-04 - accuracy: 0.9997\n",
      "Epoch 32/100\n",
      "1211/1211 [==============================] - 1s 602us/step - loss: 0.0012 - accuracy: 0.9996\n",
      "Epoch 33/100\n",
      "1211/1211 [==============================] - 1s 598us/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 34/100\n",
      "1211/1211 [==============================] - 1s 616us/step - loss: 0.0010 - accuracy: 0.9997\n",
      "Epoch 35/100\n",
      "1211/1211 [==============================] - 1s 585us/step - loss: 8.8095e-04 - accuracy: 0.9997\n",
      "Epoch 36/100\n",
      "1211/1211 [==============================] - 1s 583us/step - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 37/100\n",
      "1211/1211 [==============================] - 1s 610us/step - loss: 9.9150e-04 - accuracy: 0.9997\n",
      "Epoch 38/100\n",
      "1211/1211 [==============================] - 1s 606us/step - loss: 7.0508e-04 - accuracy: 0.9998\n",
      "Epoch 39/100\n",
      "1211/1211 [==============================] - 1s 592us/step - loss: 7.2402e-04 - accuracy: 0.9997\n",
      "Epoch 40/100\n",
      "1211/1211 [==============================] - 1s 579us/step - loss: 9.6720e-04 - accuracy: 0.9997\n",
      "Epoch 41/100\n",
      "1211/1211 [==============================] - 1s 609us/step - loss: 6.5933e-04 - accuracy: 0.9998\n",
      "Epoch 42/100\n",
      "1211/1211 [==============================] - 1s 698us/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 43/100\n",
      "1211/1211 [==============================] - 1s 643us/step - loss: 8.7965e-04 - accuracy: 0.9998\n",
      "Epoch 44/100\n",
      "1211/1211 [==============================] - 1s 595us/step - loss: 8.0509e-04 - accuracy: 0.9998\n",
      "Epoch 45/100\n",
      "1211/1211 [==============================] - 1s 580us/step - loss: 7.0583e-04 - accuracy: 0.9998\n",
      "Epoch 46/100\n",
      "1211/1211 [==============================] - 1s 567us/step - loss: 8.0340e-04 - accuracy: 0.9997\n",
      "Epoch 47/100\n",
      "1211/1211 [==============================] - 1s 580us/step - loss: 6.3625e-04 - accuracy: 0.9998\n",
      "Epoch 48/100\n",
      "1211/1211 [==============================] - 1s 586us/step - loss: 6.4602e-04 - accuracy: 0.9998\n",
      "Epoch 49/100\n",
      "1211/1211 [==============================] - 1s 595us/step - loss: 7.7225e-04 - accuracy: 0.9997\n",
      "Epoch 50/100\n",
      "1211/1211 [==============================] - 1s 617us/step - loss: 7.4234e-04 - accuracy: 0.9998\n",
      "Epoch 51/100\n",
      "1211/1211 [==============================] - 1s 609us/step - loss: 6.3730e-04 - accuracy: 0.9998\n",
      "Epoch 52/100\n",
      "1211/1211 [==============================] - 1s 592us/step - loss: 6.2844e-04 - accuracy: 0.99980s - loss: 6.0477e-04 - \n",
      "Epoch 53/100\n",
      "1211/1211 [==============================] - 1s 591us/step - loss: 7.9826e-04 - accuracy: 0.9997\n",
      "Epoch 54/100\n",
      "1211/1211 [==============================] - 1s 563us/step - loss: 6.0857e-04 - accuracy: 0.9998\n",
      "Epoch 55/100\n",
      "1211/1211 [==============================] - 1s 574us/step - loss: 5.5806e-04 - accuracy: 0.9998\n",
      "Epoch 56/100\n",
      "1211/1211 [==============================] - 1s 612us/step - loss: 5.5875e-04 - accuracy: 0.9998\n",
      "Epoch 57/100\n",
      "1211/1211 [==============================] - 1s 756us/step - loss: 8.3888e-04 - accuracy: 0.9997\n",
      "Epoch 58/100\n",
      "1211/1211 [==============================] - 1s 697us/step - loss: 6.1619e-04 - accuracy: 0.9998\n",
      "Epoch 59/100\n",
      "1211/1211 [==============================] - 1s 608us/step - loss: 5.1949e-04 - accuracy: 0.9998\n",
      "Epoch 60/100\n",
      "1211/1211 [==============================] - 1s 599us/step - loss: 7.6310e-04 - accuracy: 0.9998\n",
      "Epoch 61/100\n",
      "1211/1211 [==============================] - 1s 570us/step - loss: 4.1015e-04 - accuracy: 0.9999\n",
      "Epoch 62/100\n",
      "1211/1211 [==============================] - 1s 583us/step - loss: 5.4300e-04 - accuracy: 0.9998\n",
      "Epoch 63/100\n",
      "1211/1211 [==============================] - 1s 567us/step - loss: 6.1157e-04 - accuracy: 0.9998\n",
      "Epoch 64/100\n",
      "1211/1211 [==============================] - 1s 571us/step - loss: 3.9391e-04 - accuracy: 0.9999\n",
      "Epoch 65/100\n",
      "1211/1211 [==============================] - 1s 570us/step - loss: 4.9532e-04 - accuracy: 0.9998\n",
      "Epoch 66/100\n",
      "1211/1211 [==============================] - 1s 598us/step - loss: 5.5991e-04 - accuracy: 0.9998\n",
      "Epoch 67/100\n",
      "1211/1211 [==============================] - 1s 565us/step - loss: 4.2658e-04 - accuracy: 0.9999\n",
      "Epoch 68/100\n",
      "1211/1211 [==============================] - 1s 563us/step - loss: 4.7084e-04 - accuracy: 0.9998\n",
      "Epoch 69/100\n",
      "1211/1211 [==============================] - 1s 570us/step - loss: 4.1279e-04 - accuracy: 0.9998\n",
      "Epoch 70/100\n",
      "1211/1211 [==============================] - 1s 585us/step - loss: 3.1253e-04 - accuracy: 0.9999\n",
      "Epoch 71/100\n",
      "1211/1211 [==============================] - 1s 584us/step - loss: 4.7736e-04 - accuracy: 0.9999\n",
      "Epoch 72/100\n",
      "1211/1211 [==============================] - 1s 570us/step - loss: 4.4051e-04 - accuracy: 0.9999\n",
      "Epoch 73/100\n",
      "1211/1211 [==============================] - 1s 570us/step - loss: 3.7757e-04 - accuracy: 0.9999\n",
      "Epoch 74/100\n",
      "1211/1211 [==============================] - 1s 565us/step - loss: 5.1777e-04 - accuracy: 0.9998\n",
      "Epoch 75/100\n",
      "1211/1211 [==============================] - 1s 572us/step - loss: 5.4973e-04 - accuracy: 0.9998\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1211/1211 [==============================] - 1s 600us/step - loss: 2.6717e-04 - accuracy: 0.9999\n",
      "Epoch 77/100\n",
      "1211/1211 [==============================] - 1s 567us/step - loss: 3.8681e-04 - accuracy: 0.9999\n",
      "Epoch 78/100\n",
      "1211/1211 [==============================] - 1s 578us/step - loss: 4.4210e-04 - accuracy: 0.9998\n",
      "Epoch 79/100\n",
      "1211/1211 [==============================] - 1s 568us/step - loss: 3.8907e-04 - accuracy: 0.9999\n",
      "Epoch 80/100\n",
      "1211/1211 [==============================] - 1s 583us/step - loss: 5.4262e-04 - accuracy: 0.9998\n",
      "Epoch 81/100\n",
      "1211/1211 [==============================] - 1s 562us/step - loss: 4.0928e-04 - accuracy: 0.9999\n",
      "Epoch 82/100\n",
      "1211/1211 [==============================] - 1s 574us/step - loss: 3.4917e-04 - accuracy: 0.9999\n",
      "Epoch 83/100\n",
      "1211/1211 [==============================] - 1s 582us/step - loss: 5.7662e-04 - accuracy: 0.9998\n",
      "Epoch 84/100\n",
      "1211/1211 [==============================] - 1s 565us/step - loss: 3.6163e-04 - accuracy: 0.9999\n",
      "Epoch 85/100\n",
      "1211/1211 [==============================] - 1s 563us/step - loss: 5.2636e-04 - accuracy: 0.9998\n",
      "Epoch 86/100\n",
      "1211/1211 [==============================] - 1s 565us/step - loss: 3.6687e-04 - accuracy: 0.9999\n",
      "Epoch 87/100\n",
      "1211/1211 [==============================] - 1s 570us/step - loss: 4.4976e-04 - accuracy: 0.9999\n",
      "Epoch 88/100\n",
      "1211/1211 [==============================] - 1s 563us/step - loss: 4.0084e-04 - accuracy: 0.9998\n",
      "Epoch 89/100\n",
      "1211/1211 [==============================] - 1s 569us/step - loss: 3.1375e-04 - accuracy: 0.9999\n",
      "Epoch 90/100\n",
      "1211/1211 [==============================] - 1s 565us/step - loss: 2.8344e-04 - accuracy: 0.9999\n",
      "Epoch 91/100\n",
      "1211/1211 [==============================] - 1s 562us/step - loss: 5.1443e-04 - accuracy: 0.9998\n",
      "Epoch 92/100\n",
      "1211/1211 [==============================] - 1s 567us/step - loss: 4.2135e-04 - accuracy: 0.9999\n",
      "Epoch 93/100\n",
      "1211/1211 [==============================] - 1s 562us/step - loss: 3.3124e-04 - accuracy: 0.9999\n",
      "Epoch 94/100\n",
      "1211/1211 [==============================] - 1s 561us/step - loss: 2.6333e-04 - accuracy: 0.9999\n",
      "Epoch 95/100\n",
      "1211/1211 [==============================] - 1s 564us/step - loss: 2.5925e-04 - accuracy: 0.9999\n",
      "Epoch 96/100\n",
      "1211/1211 [==============================] - 1s 563us/step - loss: 3.4869e-04 - accuracy: 0.9999\n",
      "Epoch 97/100\n",
      "1211/1211 [==============================] - 1s 562us/step - loss: 4.9991e-04 - accuracy: 0.9999\n",
      "Epoch 98/100\n",
      "1211/1211 [==============================] - 1s 563us/step - loss: 2.5614e-04 - accuracy: 0.9999\n",
      "Epoch 99/100\n",
      "1211/1211 [==============================] - 1s 565us/step - loss: 4.3317e-04 - accuracy: 0.9998\n",
      "Epoch 100/100\n",
      "1211/1211 [==============================] - 1s 562us/step - loss: 3.6342e-04 - accuracy: 0.9999\n",
      "1336/1336 [==============================] - 1s 405us/step - loss: 0.0149 - accuracy: 0.9993\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-67250ed4110d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\ad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[0;32m   2379\u001b[0m                        \u001b[1;34m'an `input_shape` argument in the first layer(s) for '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2380\u001b[0m                        'automatic build.')\n\u001b[1;32m-> 2381\u001b[1;33m     layer_utils.print_summary(self,\n\u001b[0m\u001b[0;32m   2382\u001b[0m                               \u001b[0mline_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2383\u001b[0m                               \u001b[0mpositions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpositions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\layer_utils.py\u001b[0m in \u001b[0;36mprint_summary\u001b[1;34m(model, line_length, positions, print_fn)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0msequential_like\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m     \u001b[0mline_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline_length\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;36m65\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m     \u001b[0mpositions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpositions\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m.45\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m.85\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpositions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 모델생성 3 : 활성화 함수 relu, sigmoid 은닉층 추가\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(32, activation=\"relu\", input_dim=(X_train.shape[1])))\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation ='sigmoid'))\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train, epochs = 100, batch_size=200, verbose=1)\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.legend(['accuracy'])\n",
    "\n",
    "model.evaluate(X_test, Y_test)\n",
    "model.summary(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511b5d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
